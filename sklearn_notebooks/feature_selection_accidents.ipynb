{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn example: 1. Recursive feature elimination with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple original: <br>\n",
    "https://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, on teste un exemple de scikit-learn sur notre jeu de données. Nous allons faire une séléction de variables pour déterminer, parmi les 54 variables disponibles, 20 variables qui ont plus d'importance dans la prédiction de la variable *grav*, qui indique la gravité de l'accident."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse et preprocessing du jeu de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://static.data.gouv.fr/resources/bases-de-donnees-annuelles-des-accidents-corporels-de-la-circulation-routiere-annees-de-2005-a-2019/20210317-145928/accidents-corp-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats du `Pandas Profiling` nous guident dans le preprocessing. <br>\n",
    "1. On observe que le jeu de données a 7.3% de **valeurs manquantes** au total. Nous faisons le choix d'éliminer les colonnes contenant plus de 90% de valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[col for col in data.columns if data[col].isna().sum()/len(data)>0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Le jeu de données contient des **variables** qui ne sont **pas exploitables** par le jeu de données, et que nous faisons le choix d'éliminer:\n",
    "- les identifiants (comme la colonne *id_vehicule*)\n",
    "- les colonnes à valeur constantes (colonne *an*)\n",
    "- les colonnes à haute cardinalité, c'est à dire ayant un trop grand nombre de catégories (colonne *adr*). Pour en savoir plus sur la haute cardinalité: https://project.inria.fr/dirtydata/presentation-useful-results-from-dirtydata-for-machine-learning-in-python-on-non-curated-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupported_var = ['an','Num_Acc','id_vehicule','adr','com','pr','pr1','dep','voie','v1']\n",
    "data = data.drop(columns=unsupported_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On modifie les colonnes *lat* et *long* pour avoir bien des valeures numériques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lat'] = data['lat'].str.replace(',', '.', regex=True)\n",
    "data['lat'] = data['lat'].astype(float)\n",
    "data['long'] = data['long'].str.replace(',', '.', regex=True)\n",
    "data['long'] = data['long'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et on définit une nouvelle variable pour l'heure de l'accident, à partir de la variable *hrmn*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour(n):\n",
    "    n=str(n)\n",
    "    if len(n)<4:\n",
    "        n='0'+n\n",
    "    return int(n[:2])\n",
    "\n",
    "data['heure']=data['hrmn'].apply(hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['hrmn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séléction et encoding de la target variable et des variables explicatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['grav'].values\n",
    "X = data.drop(columns=['grav'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = label_enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait du encoding des variables catégorielles. <br>\n",
    "On fait le choix de faire du **CardinalEncoding**, pour éviter d'aumenter la dimension du jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_var = ['num_veh','place','catu','sexe','trajet','secu1','secu2','secu3','locp','actp',\n",
    "                   'etatp','senc','catv','obs','obsm','choc','manv','motor','lum','agg','int','atm','col'\n",
    "                  ,'catr','circ','vosp','prof','plan','surf','infra','situ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_enc = OrdinalEncoder(handle_unknown = 'error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_trans =  make_column_transformer((ordinal_enc,categorical_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = columns_trans.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "# Original code: https://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py\n",
    "# Adapted by: Giulia Santarsieri <giulia.santarsieri@data.gouv.fr> for DGML\n",
    "print(__doc__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "svc = SVC(kernel=\"linear\")\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "\n",
    "min_features_to_select = 1  # Minimum number of features to consider\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2),\n",
    "              scoring='accuracy',\n",
    "              min_features_to_select=min_features_to_select)\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(min_features_to_select,\n",
    "               len(rfecv.grid_scores_) + min_features_to_select),\n",
    "         rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn example: 2. Recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "# Code adapted by: Giulia Santarsieri <giulia.santarsieri@data.gouv.fr> for DGML\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the digits dataset\n",
    "#digits = load_digits()\n",
    "#X = digits.images.reshape((len(digits.images), -1))\n",
    "#y = digits.target\n",
    "\n",
    "# Create the RFE object and rank each pixel\n",
    "svc = SVC(kernel=\"linear\", C=1)\n",
    "rfe = RFE(estimator=svc, n_features_to_select=20, step=1) #20 variables\n",
    "rfe.fit(X, y)\n",
    "#ranking = rfe.ranking_.reshape(digits.images[0].shape)\n",
    "ranking = rfe.ranking_\n",
    "\n",
    "# Plot pixel ranking\n",
    "plt.matshow(ranking, cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.title(\"Ranking of pixels with RFE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

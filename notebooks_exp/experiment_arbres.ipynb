{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning pour prédire l'état de santé d'un arbre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, vous trouvez notre code d'entraînement et validation automatique d'algorithmes de Machine Learning pour prédire l'état de santé d'un arbre(C0 = emplacement vide ; C1 = arbre sain, de bonne vigueur ; C2 = arbre présentant des lésions sans gravité ; C3 = arbre présentant des lésions importantes ; C4 = arbre présentant des lésions importantes et évolutives ; C5 = arbre présentant des lésions irrémédiables nécessitant un abattage ; C6 = souche) à partir du jeu de données *Arbres urbains*.\n",
    "\n",
    "**dataset:** https://www.data.gouv.fr/fr/datasets/arbres-urbains/<br>\n",
    "**tâche:** Classification (Classification multi-classe)<br>\n",
    "**target variable:** *classification_diagnostic*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "#pour l'entraînement automatique:\n",
    "from supervised.automl import AutoML\n",
    "#pour générer un rapport html des résultats:\n",
    "import IPython\n",
    "import markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des données\n",
    "\n",
    "On importe le dataset à partir de son url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.data.gouv.fr/fr/datasets/r/96f4164d-956d-4c1c-b161-68724eb0ccdc'\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "Grâce à `Pandas Profiling`(https://giuliasantarsieri.github.io/open_ML/profilings/arbres_urbains.html), on a pu identifier les colonnes inutiles et non supportées. On les soustrait du dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['ID_ARBRE','commune','controle','champignon_collet', 'insecte_collet','champignon_collet', 'insecte_collet','champignon_tronc', 'insecte_tronc',\n",
    "       'fissure_tronc','ecorce_incluse_houppier','type_delai_1', 'delai_annee_programmation',\n",
    "       'type_delai_2', 'delai_preconisation_2', 'delai_saison_programmation_2',\n",
    "       'delai_annee_programmation_2', 'reference_photo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait le choix d'éliminer les variables ayant plus de 80% de valeurs manquantes et de faire de l'imputation des valeurs manquantes pour les autres colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[col for col in data.columns if data[col].isna().sum()/len(data)>0.8])\n",
    "\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "data[['cote_voirie', 'prescription_1', 'prescription_2']] = imp.fit_transform(data[['cote_voirie', 'prescription_1', 'prescription_2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/test splitting\n",
    "\n",
    "On définit la variable réponse et les variables explicatives. On partage le dataset en dataset d'entraînement et de test. Attention, AutoML nécessite d'un partage 75%/25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['classification_diagnostic'].values\n",
    "X = data.drop(columns=['classification_diagnostic'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. AutoML\n",
    "\n",
    "On entraîne, test et valide automatiquement plusieurs algorithmes de ML sur le dataset avec AutoML (plus d'infos ici: https://supervised.mljar.com/) et on génère un html des métriques et des paramètres du modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML(total_time_limit=5*60,mode='Explain',random_state=42)\n",
    "#fit model\n",
    "automl.fit(X_train,y_train)\n",
    "#predictions\n",
    "predictions = automl.predict(X_test)\n",
    "#generate html report\n",
    "automl.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing fait par AutoML\n",
    "\n",
    "Il n'est pas évident de comprendre, à partir du rapport html qui est généré, quelles tâches de preprocessing sont faites dans la **pipeline de AutoML** qui permet d' aboutir aux résultats observés. <br>\n",
    "Pour mieux comprendre les résultats, on peut s'intéresser au fichier `framework.json` de chaque modèle. Par exemple, on peut consulter ce fichier pour le modèle `Xgboost` ici:\n",
    "https://github.com/etalab-ia/DGML/blob/main/docs/automodels/c763b24a-a0fe-4e77-9586-3d5453c631cd/4_Default_Xgboost/framework.json<br>\n",
    "On observe:\n",
    "1. L'imputation des **valeurs manquantes** est faite en remplaçant par la valeur médiane\n",
    "2. L'**encoding** des variables catégorielles est fait en transformant le nom de chaque catégorie en un entier\n",
    "\n",
    "Ces informations sont disponibles pour tous les algorithmes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning pour prédire le prix par nuit d'un logement Airbnb à Bordeaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, vous trouvez notre code d'entrainement et validation automatique d'algorithmes de Machine Learning pour prédire le prix par nuit d'un logement Airbnb à Bordeaux à partir du jeu de données *liste des logements proposés en Airbnb sur Bordeaux*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dataset:** https://www.data.gouv.fr/en/datasets/liste-des-logements-proposes-en-airbnb-sur-bordeaux/ <br>\n",
    "**tâche:** Régression <br>\n",
    "**target variable:** *PrixNuitee*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "#pour l'entraînement automatique:\n",
    "from supervised.automl import AutoML\n",
    "#pour générer un rapport html des résultats:\n",
    "import IPython\n",
    "import markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des données\n",
    "\n",
    "On importe le dataset à partir de son url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.data.gouv.fr/fr/datasets/r/123e1c18-37e0-4147-ad65-768320387800\"\n",
    "data_airbnb = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On élimine une colonne redondante et les colonnes inutiles détectées par `Pandas Profiling` (https://giuliasantarsieri.github.io/open_ML/profilings/data_airbnb.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_airbnb = data_airbnb.drop(columns=['prix_nuitee']) \n",
    "data_airbnb = data_airbnb.drop(columns=['Url','Resume','Shampooing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train/test splitting\n",
    "\n",
    "On n'effectue pas de séléction de variables. On définit la variable réponse et les variables explicatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_airbnb['PrixNuitee'].values\n",
    "X = data_airbnb.drop(columns=['PrixNuitee'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On partage le dataset en dataset d'entraînement et de test. Attention, AutoML nécessite d'un partage 75%/25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AutoML\n",
    "\n",
    "On entraîne, test et valide automatiquement plusieurs algorithmes de ML sur le dataset avec AutoML (plus d'infos ici: https://supervised.mljar.com/) et on génère un html des métriques et des paramètres du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML(total_time_limit=5*60, mode='Explain')\n",
    "#fit model\n",
    "automl.fit(X_train,y_train)\n",
    "#predictions\n",
    "predictions = automl.predict(X_test)\n",
    "#generate html report\n",
    "automl.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing fait par AutoML\n",
    "\n",
    "Il n'est pas évident de comprendre, à partir du rapport html qui est généré, quelles tâches de preprocessing sont faites dans la **pipeline de AutoML** qui permet d' aboutir aux résultats observés.  <br>\n",
    "Pour mieux comprendre les résultats, on peut s'intéresser au fichier `framework.json` de chaque modèle. Par exemple, on peut consulter ce fichier pour le modèle `Xgboost` ici:\n",
    "https://github.com/etalab-ia/DGML/blob/main/docs/automodels/123e1c18-37e0-4147-ad65-768320387800/4_Default_Xgboost/framework.json <br>\n",
    "On observe:\n",
    "1. L'imputation des **valeurs manquantes** est faite en remplaçant par la valeur médiane\n",
    "2. L'**encoding** des variables catégorielles est fait en transformant le nom de chaque catégorie en un entier\n",
    "3. Les colonnes contenant du long **texte** sont transformées à l'aide de [`TfidVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "\n",
    "Ces informations sont disponibles pour tous les algorithmes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

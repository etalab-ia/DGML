{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning sur des données socio-démographiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, vous trouvez notre code d'entrainement et validation automatique d'algorithmes de Machine Learning pour prédire le nombre de logements sociaux dans une zone géographique de France métropolitaine à partir du jeu de données *Données carroyées issues du dispositif sur les revenus localisés fiscaux et sociaux (FiLoSoFi)*.\n",
    "\n",
    "**dataset:** https://www.data.gouv.fr/fr/datasets/donnees-carroyees-issues-du-dispositif-sur-les-revenus-localises-fiscaux-et-sociaux-filosofi/<br>\n",
    "**tâche:** Régression<br>\n",
    "**target variable:** *Log_soc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "#pour l'entraînement automatique:\n",
    "from supervised.automl import AutoML\n",
    "#pour générer un rapport html des résultats:\n",
    "import IPython\n",
    "import markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe le dataset téléchargeable ici: https://www.insee.fr/fr/statistiques/4176281?sommaire=4176305#consulter et on élimine les colonnes de valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_metr = '/home/giulia/data/Filosofi2015_carreaux_niveau_naturel_metropole.csv'\n",
    "carreaux_metr = pd.read_csv(path_metr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carreaux_metr = carreaux_metr.drop(columns=['Ind_inc','Log_inc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train/test splitting\n",
    "\n",
    "On n'effectue pas de séléction de variables. On définit la variable réponse et les variables explicatives.\n",
    "On partage le dataset en dataset d'entraînement et de test. Attention, AutoML nécessite d'un partage 75%/25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = carreaux_metr['Log_soc'].values\n",
    "X = carreaux_metr.drop(columns=['Log_soc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AutoML\n",
    "\n",
    "On entraîne, test et valide automatiquement plusieurs algorithmes de ML sur le dataset avec AutoML (plus d'infos ici: https://supervised.mljar.com/) et on génère un html des métriques et des paramètres du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML(total_time_limit=5*60, mode='Explain',random_state=42)\n",
    "#fit model\n",
    "automl.fit(X_train,y_train)\n",
    "#predictions\n",
    "predictions = automl.predict(X_test)\n",
    "#generate html report\n",
    "automl.report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning pour prédire une valeur foncière"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, vous trouvez notre code d'entrainement et validation automatique d'algorithmes de Machine Learning pour prédire une valeur foncière à partir du jeu de données *Demandes de valeurs foncières* du premier trimestre de 2020.\n",
    "\n",
    "**dataset:** https://www.data.gouv.fr/fr/datasets/demandes-de-valeurs-foncieres/<br>\n",
    "**tâche:** Régression<br>\n",
    "**target variable:** *Valeur fonciere*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.impute import SimpleImputer\n",
    "#pour l'entraînement automatique:\n",
    "from supervised.automl import AutoML\n",
    "#pour générer un rapport html des résultats:\n",
    "import IPython\n",
    "import markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des données\n",
    "\n",
    "On importe le dataset à partir de son url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (18,23,24,26,28,31,33,41) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "url_2020 = \"https://www.data.gouv.fr/fr/datasets/r/90a98de0-f562-4328-aa16-fe0dd1dca60f\"\n",
    "data_2020 = pd.read_csv(url_2020, sep='|')  #dataframe des demandes de valeurs foncières du premier trimestre de 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "### 2.1. Elimination des colonnes non supportées d'après Pandas Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2020 = data_2020.drop(columns=['1er lot','Code departement'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Modification du type des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target variable\n",
    "data_2020['Valeur fonciere'] = data_2020['Valeur fonciere'].str.replace(',', '.', regex=True)\n",
    "data_2020['Valeur fonciere'] = data_2020['Valeur fonciere'].astype(float)\n",
    "\n",
    "#variables catégorielles\n",
    "categorical_features = ['Nature culture', 'Type local','Code type local', 'Nature mutation']\n",
    "\n",
    "for c in categorical_features:\n",
    "    data_2020[c] = data_2020[c].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Imputation des valeurs manquantes\n",
    "\n",
    "Pour pouvoir entraîner nos modèles, on élimine les lignes du datasets correspondant à des valeurs manquantes de la variable réponse. On élimine également les variables avec plus de 90% de valeurs manquantes et on fait de l'imputation de valeurs manquantes sur les autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2020 = data_2020.drop(columns=[col for col in data_2020.columns if data_2020[col].isna().sum()/len(data_2020)>0.9])\n",
    "data_2020 = data_2020[data_2020['Valeur fonciere'].isna()==False]\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "data_2020[['Type de voie', 'Type local', 'Surface reelle bati', 'Nombre pieces principales', 'Nature culture',\n",
    "             'Surface terrain']]=imp.fit_transform(data_2020[['Type de voie','Type local','Surface reelle bati','Nombre pieces principales','Nature culture','Surface terrain']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/test splitting\n",
    "\n",
    "On définit la variable réponse et les variables explicatives.<br>\n",
    "On partage le dataset en dataset d'entraînement et de test. Attention, AutoML nécessite d'un partage 75%/25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_2020['Valeur fonciere'].values\n",
    "X = data_2020.drop(columns=['Valeur fonciere'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.AutoML\n",
    "\n",
    "On entraîne, test et valide automatiquement plusieurs algorithmes de ML sur le dataset avec AutoML (plus d'infos ici: https://supervised.mljar.com/) et on génère un html des métriques et des paramètres du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML(total_time_limit=6*60,mode='Explain',random_state=42)\n",
    "#fit model\n",
    "automl.fit(X_train,y_train)\n",
    "#predictions\n",
    "predictions = automl.predict(X_test)\n",
    "#generate html report\n",
    "automl.report()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning pour prédire les résultats de contrôles sanitaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, vous trouvez notre code d'entrainement et validation automatique d'algorithmes de Machine Learning pour prédire les résultats de contrôles sanitaires à partir du jeu de données *Résultats des contrôles officiels sanitaires : dispositif d’information « Alim’confiance »*.\n",
    "\n",
    "**dataset:**https://www.data.gouv.fr/fr/datasets/resultats-des-controles-officiels-sanitaires-dispositif-dinformation-alimconfiance/ <br>\n",
    "**tâche:** Classification (Classifcation multi-classe)<br>\n",
    "**target variable:** *Synthese_eval_sanit*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import io\n",
    "import requests\n",
    "#pour l'entraînement automatique:\n",
    "from supervised.automl import AutoML\n",
    "#pour générer un rapport html des résultats:\n",
    "import IPython\n",
    "import markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des données\n",
    "\n",
    "On importe le dataset à partir de son url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_cont_san = \"https://www.data.gouv.fr/fr/datasets/r/fff0cc27-977b-40d5-9c11-f7e4e79a0b72\" #données brutes en csv\n",
    "r = requests.get(url_cont_san,allow_redirects=True)\n",
    "df=pd.read_csv(io.StringIO(r.content.decode('utf-8')), sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"https://www.data.gouv.fr/fr/datasets/r/fff0cc27-977b-40d5-9c11-f7e4e79a0b72\",sep=\";\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing et feature engineering\n",
    "\n",
    "Le code de cette partie à été partiellement pris du notebook fait par Julien Denes en Introduction au ML: https://colab.research.google.com/drive/1OgqIFNCkEi4YL9Xr7R0yegWbhZGG0HiV#scrollTo=YkR83PK6V_Nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dans la colonne 'filtre', plusieurs filtres sont parfois donnés.\n",
    "#on en séléctionne un seulement et on gère ses valeurs manquantes:\n",
    "df['filtre'] = df['filtre'].str.split('\\|').str[0]\n",
    "df['filtre'] = df['filtre'].fillna('NA')\n",
    "\n",
    "#modification du type des variables latitude et longitude:\n",
    "df['latitude'] = df['geores'].str.split(',').str[0].astype(float)\n",
    "df['longitude'] = df['geores'].str.split(',').str[1].astype(float)\n",
    "\n",
    "#modification du type de la variable réponse\n",
    "df['Synthese_eval_sanit'] = df['Synthese_eval_sanit'].astype('category').cat.codes\n",
    "\n",
    "#modification du type de la variable 'date d'inspection\n",
    "df['Date_inspection'] = pd.to_datetime(df['Date_inspection'], format='%Y-%m-%dT%H:%M:%S', utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#création de plusieurs nouvelles variables:\n",
    "df['has_agrement'] = pd.notnull(df['Agrement']).astype(int)\n",
    "\n",
    "#variable département:\n",
    "df['dept'] = [int(r[:2]) for r in df['Code_postal']]\n",
    "\n",
    "#variables temporelles\n",
    "df['year'] = df['Date_inspection'].dt.year\n",
    "df['month'] = df['Date_inspection'].dt.month\n",
    "df['weekday'] = df['Date_inspection'].dt.weekday\n",
    "\n",
    "#comptage et score des controles \n",
    "df['count_controls_dept'] = df.groupby('dept')['Synthese_eval_sanit'].transform(lambda x: x.count())\n",
    "df['score_controls_dept'] = df.groupby('dept')['Synthese_eval_sanit'].transform(lambda x: x.mean())\n",
    "df['count_controls_filtre'] = df.groupby('filtre')['Synthese_eval_sanit'].transform(lambda x: x.count())\n",
    "df['score_controls_filtre'] = df.groupby('filtre')['Synthese_eval_sanit'].transform(lambda x: x.mean())\n",
    "df['ods_type_activite'] = df['ods_type_activite'].fillna('NA')\n",
    "df['count_controls_activite'] = df.groupby('ods_type_activite')['Synthese_eval_sanit'].transform(lambda x: x.count())\n",
    "df['score_controls_activite'] = df.groupby('ods_type_activite')['Synthese_eval_sanit'].transform(lambda x: x.mean())\n",
    "df['count_controls_wday'] = df.groupby('weekday')['Synthese_eval_sanit'].transform(lambda x: x.count())\n",
    "df['score_controls_wday'] = df.groupby('weekday')['Synthese_eval_sanit'].transform(lambda x: x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#élimination des colonnes inutiles\n",
    "drop_cols = ['APP_Libelle_etablissement', 'Code_postal', 'SIRET', 'Libelle_commune',\n",
    "             'APP_Libelle_activite_etablissement', 'Numero_inspection', 'Date_inspection',\n",
    "             'Agrement', 'geores', 'ods_type_activite','Adresse_2_UA']\n",
    "df = df.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformation des variables catégorielles\n",
    "categorical_features = ['dept', 'filtre', 'month', 'weekday']\n",
    "\n",
    "for c in categorical_features:\n",
    "    df[c] = df[c].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/test splitting\n",
    "\n",
    "On n'effectue pas de séléction de variables. On définit la variable réponse et les variables explicatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Synthese_eval_sanit'].values\n",
    "X = df.drop(columns = ['Synthese_eval_sanit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On partage le dataset en dataset d'entraînement et de test. Attention, AutoML nécessite d'un partage 75%/25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. AutoML\n",
    "\n",
    "On entraîne, test et valide automatiquement plusieurs algorithmes de ML sur le dataset avec AutoML (plus d'infos ici: https://supervised.mljar.com/) et on génère un html des métriques et des paramètres du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML(total_time_limit=5*60,mode='Explain',random_state=42)\n",
    "#fit model\n",
    "automl.fit(X_train,y_train)\n",
    "#predictions\n",
    "predictions = automl.predict(X_test)\n",
    "#generate html report\n",
    "automl.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing fait par AutoML\n",
    "\n",
    "Il n'est pas évident de comprendre, à partir du rapport html qui est généré, quelles tâches de preprocessing sont faites dans la **pipeline de AutoML** qui permet d' aboutir aux résultats observés.  <br>\n",
    "Pour mieux comprendre les résultats, on peut s'intéresser au fichier `framework.json` de chaque modèle. Par exemple, on peut consulter ce fichier pour le modèle `Xgboost` ici:\n",
    "https://github.com/etalab-ia/DGML/blob/main/docs/automodels/c763b24a-a0fe-4e77-9586-3d5453c631cd/4_Default_Xgboost/framework.json<br>\n",
    "On observe:\n",
    "1. L'imputation des **valeurs manquantes** est faite en remplaçant par la valeur médiane\n",
    "2. Un **encoding** des variables catégorielles est fait en transformant le nom de chaque catégorie en un entier\n",
    " \n",
    "Ces informations sont disponibles pour tous les algorithmes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

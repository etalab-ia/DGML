{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning pour prédire la gravité des accidents routiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, vous trouvez notre code d'entraînement et validation automatique d'algorithmes de Machine Learning pour prédire la gravité des accidents de voiture à partir du jeu de données de **2019** de *Bases de données annuelles des accidents corporels de la circulation routière - Années de 2005 à 2019*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dataset:** https://www.data.gouv.fr/fr/datasets/bases-de-donnees-annuelles-des-accidents-corporels-de-la-circulation-routiere-annees-de-2005-a-2019/#_ <br>\n",
    "**tâche:** Classification (Classification multi-classe)<br>\n",
    "**target variable:** *grav*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous disposons de 4 datasets différents (*caracteristiques*,*lieux*,*vehicules*,*usagers*) qui contiennent des variables sur les accidents corporels et on cherche à prédire la variable *grav* de la gravité de l'accident:\n",
    "- 1: Indemne\n",
    "- 2: Tué\n",
    "- 3: Hospitalisé\n",
    "- 4: Blessé léger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "#pour l'entraînement automatique:\n",
    "from supervised.automl import AutoML\n",
    "#pour générer un rapport html des résultats:\n",
    "import IPython\n",
    "import markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des données\n",
    "\n",
    "Nous utilisons le jeux de données obtenu à partir de l'union des 4 jeux de données cités plus haut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://static.data.gouv.fr/resources/bases-de-donnees-annuelles-des-accidents-corporels-de-la-circulation-routiere-annees-de-2005-a-2019/20210317-145928/accidents-corp-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing et feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On modifie les colonnes *lat* et *long*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lat'] = data['lat'].str.replace(',', '.', regex=True)\n",
    "data['lat'] = data['lat'].astype(float)\n",
    "data['long'] = data['long'].str.replace(',', '.', regex=True)\n",
    "data['long'] = data['long'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée deux nouvelles variables donnant le moment de l'accident:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour(n):\n",
    "    n=str(n)\n",
    "    if len(n)<4:\n",
    "        n='0'+n\n",
    "    return int(n[:2])\n",
    "\n",
    "data['heure']=data['hrmn'].apply(hour)\n",
    "data['mom_acc']=pd.to_datetime(pd.DataFrame({'year': data['an'],'month': data['mois'],'day': data['jour'],'hour':data['heure']}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et une variable pour le jour de la semaine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['jour_semaine']=data['mom_acc'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature selection et train/test splitting\n",
    "\n",
    "On sélectionne les variables qui vont faire partie de notre modèle et on partage le dataset en dataset d'entraînement et de test. Attention, AutoML nécessite d'un partage 75%/25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['place','catu','sexe','trajet','secu1','secu2','secu3','locp',\n",
    "            'catv','an_nais','mois',\n",
    "            'occutc','obs','obsm','choc','manv',\n",
    "            'lum','agg','int','atm','col',\n",
    "            'catr','circ','vosp','prof','plan',\n",
    "            'surf','infra','situ','lat','long','heure','mom_acc','jour_semaine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['grav'].values\n",
    "X = data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. AutoML\n",
    "\n",
    "On entraîne, test et valide automatiquement plusieurs algorithmes de ML sur le dataset avec AutoML (plus d'infos ici: https://supervised.mljar.com/) et on génère un html des métriques et des paramètres du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML(algorithms=['Random Forest', 'Xgboost', 'Decision Tree', 'Baseline', 'Linear'],mode='Explain',random_state=42,explain_level=0)\n",
    "#fit model\n",
    "automl.fit(X_train,y_train)\n",
    "#predictions\n",
    "predictions = automl.predict(X_test)\n",
    "#generate html report\n",
    "automl.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing fait par AutoML\n",
    "\n",
    "Il n'est pas évident de comprendre, à partir du rapport html qui est généré, quelles tâches de preprocessing sont faites dans la **pipeline de AutoML** qui permet d' aboutir aux résultats observés.  <br>\n",
    "Pour mieux comprendre les résultats, on peut s'intéresser au fichier `framework.json` de chaque modèle. Par exemple, on peut consulter ce fichier pour le modèle `Xgboost` ici:\n",
    "https://github.com/etalab-ia/DGML/blob/main/docs/automodels/6af37c98-0933-4ae4-8380-5f63212fb52a/3_Default_Xgboost/framework.json <br>\n",
    "On observe:\n",
    "1. L'imputation des **valeurs manquantes** est faite en remplaçant par la valeur médiane\n",
    "2. Une **transformation des dates** est effectuée\n",
    "3. Un **encoding** des variables catégorielles est fait en transformant le nom de chaque catégorie en un entier\n",
    "\n",
    "Ces informations sont disponibles pour tous les algorithmes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
